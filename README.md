# Medical-Images-segmentation
`Цель проекта:`
Разработка и реализация методов аугментации изображений здоровых лёгких для увеличения разнообразия и объёма данных, с последующим использованием этих данных для обучения моделей сегментации. Это позволит улучшить качество предсказаний и повысить надёжность анализа медицинских изображений.

Этапы проекта:
`Подготовка данных:`

Собирается набор данных изображений здоровых лёгких (рентгеновские снимки или КТ).
Данные подготавливаются к процессу аугментации, что включает их предварительную обработку (масштабирование, нормализация).

`Аугментация данных:`

Применение библиотеки Albumentations для увеличения объёма данных путём преобразований изображений (повороты, изменения яркости, контраста, добавление шума, зеркальные отражения).
Генерация новых вариаций изображений позволяет увеличить объём данных, что особенно полезно в условиях малого набора исходных изображений.

`Построение модели:`

Использование TensorFlow и Keras для построения нейросетевой модели сегментации.
Модель включает свёрточные слои (Conv2D) и слои активации (ReLU), а также нормализацию (BatchNormalization) для повышения производительности.
Используется оптимизатор Adam для эффективного обучения модели.

`Обучение модели:`

Модель обучается на исходных и аугментированных данных, что позволяет улучшить её обобщающие способности.
Осуществляется регулярная проверка точности и потерь на обучающей и проверочной выборках с целью мониторинга прогресса.

`Визуализация и оценка:`

Построение графиков точности и потерь на протяжении обучения.
Визуализация результатов работы модели с использованием метода display(), который показывает оригинальные изображения, маски и предсказанные моделью результаты.
Сравнение качества работы модели на исходных и аугментированных данных.

`Тестирование и анализ результатов:`

После завершения обучения модель тестируется на новых данных для проверки её точности.
Анализируется влияние аугментации на точность предсказаний, что помогает оценить эффективность метода.

[Открыть в Google Colab](https://colab.research.google.com/drive/12csQra_mahG4nrfCfGEkGhH-Ndc7D1r0?usp=sharing)
